{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpuxI0vmyzbL"
      },
      "outputs": [],
      "source": [
        "# gemini api\n",
        "# text generation\n",
        "# Q&A\n",
        "# Image to text\n",
        "# write a blog based on image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IU1Q1CmzjeU",
        "outputId": "f87ac7a4-6908-4724-de30-4fd224755ae3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import Markdown, display\n",
        "\n"
      ],
      "metadata": {
        "id": "J17D-IoCz4ff"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removed some special charactor like * , /n etc\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "input_text = \"This is a • sample text with bullet points.\"\n",
        "result = to_markdown(input_text)\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "Ox8PwhQn2RYL",
        "outputId": "1c122423-1814-4c39-89d6-48b6a066c041"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> This is a   * sample text with bullet points."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google api kay\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "lznpItjR3yF7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect gemini api key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "fOA67p0i4BmI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of model present in gemini\n",
        "for model in genai.list_models():\n",
        "  print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TgAOD3BD4B0I",
        "outputId": "feb132b1-70bb-433a-a737-fb04dda4af58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/chat-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 Chat (Legacy)',\n",
            "      description='A legacy text-only model optimized for chat conversations',\n",
            "      input_token_limit=4096,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
            "      temperature=0.25,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/text-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 (Legacy)',\n",
            "      description='A legacy model that understands text and generates text as an output',\n",
            "      input_token_limit=8196,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
            "      temperature=0.7,\n",
            "      max_temperature=None,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-gecko-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding Gecko',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=1024,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      max_temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Latest',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
            "                   'model.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
            "                   'model that supports tuning.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=0.9,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-vision-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-1.5-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro Latest',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro 001',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-002',\n",
            "      base_model_id='',\n",
            "      version='002',\n",
            "      display_name='Gemini 1.5 Pro 002',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-exp-0801',\n",
            "      base_model_id='',\n",
            "      version='exp-0801',\n",
            "      display_name='Gemini 1.5 Pro Experimental 0801',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-pro-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='exp-0827',\n",
            "      display_name='Gemini 1.5 Pro Experimental 0827',\n",
            "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
            "      input_token_limit=2000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash Latest',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 001',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-001-tuning',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 001 Tuning',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=16384,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='exp-0827',\n",
            "      display_name='Gemini 1.5 Flash Experimental 0827',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=64)\n",
            "Model(name='models/gemini-1.5-flash-002',\n",
            "      base_model_id='',\n",
            "      version='002',\n",
            "      display_name='Gemini 1.5 Flash 002',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash-8B',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash-8B 001',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash-8B Latest',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
            "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding 001',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      max_temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/text-embedding-004',\n",
            "      base_model_id='',\n",
            "      version='004',\n",
            "      display_name='Text Embedding 004',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      max_temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      max_temperature=None,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "zfKu801P6OQD",
        "outputId": "8b7a7f50-383c-44dd-f286-d8d9ddd2ad0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-pro')"
      ],
      "metadata": {
        "id": "EIxxP4ae6pbY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = model.generate_content(\"what is AI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "n_b0Qvzj60CB",
        "outputId": "b3055945-2f3f-44c4-d3d3-efdd95dff2ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 173 ms, sys: 15.4 ms, total: 188 ms\n",
            "Wall time: 12.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLkQmOkc7JHW",
        "outputId": "b01a904f-43eb-4126-93a4-73bd745de689"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=protos.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"**Artificial Intelligence (AI)**\\n\\nAI refers to the development and use of computer systems that are able to perform tasks that typically require human intelligence, such as:\\n\\n* **Learning:** Acquiring and understanding new information from data.\\n* **Reasoning:** Applying logic and deduction to solve problems or make decisions.\\n* **Problem-solving:** Defining and solving complex problems.\\n* **Perception:** Understanding and interpreting sensory data, such as images or speech.\\n* **Natural language processing:** Understanding and generating human language.\\n\\n**Types of AI:**\\n\\n* **Narrow AI:** Designed to perform specific tasks, such as playing chess or translating languages.\\n* **General AI:** Hypothetical machines that can perform a wide range of intellectual tasks at the level of a human.\\n* **Super AI:** AI that exceeds human intelligence in all domains.\\n\\n**Methods of AI:**\\n\\n* **Machine Learning:** Algorithms that learn patterns and make predictions from data.\\n* **Deep Learning:** A subset of machine learning that uses artificial neural networks to solve complex problems.\\n* **Natural Language Processing (NLP):** Techniques that allow computers to understand and process human language.\\n* **Computer Vision:** Methods for computers to analyze and interpret images and videos.\\n\\n**Applications of AI:**\\n\\nAI is used in a wide range of industries and applications, including:\\n\\n* Healthcare (diagnosis, treatment)\\n* Finance (fraud detection, risk assessment)\\n* Manufacturing (quality control, automation)\\n* Transportation (self-driving cars, route optimization)\\n* Customer service (chatbots, recommendation systems)\\n\\n**Benefits of AI:**\\n\\n* **Increased efficiency and productivity:** Automating tasks and providing insights.\\n* **Improved decision-making:** Providing data-driven recommendations and predictions.\\n* **Enhanced user experiences:** Personalizing interactions and making them more convenient.\\n* **New product and service innovation:** Enabling the development of previously impossible solutions.\\n\\n**Challenges and Ethical Considerations of AI:**\\n\\n* **Bias:** AI systems can inherit biases from their training data.\\n* **Job displacement:** AI can automate certain tasks, leading to job losses.\\n* **Privacy concerns:** AI can collect and analyze large amounts of data, raising privacy issues.\\n* **Misuse of AI:** AI can be used for malicious purposes, such as surveillance or manipulation.\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": \"STOP\",\n",
              "          \"index\": 0,\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            },\n",
              "            {\n",
              "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
              "              \"probability\": \"NEGLIGIBLE\"\n",
              "            }\n",
              "          ]\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 4,\n",
              "        \"candidates_token_count\": 477,\n",
              "        \"total_token_count\": 481\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "fNfSHcnR7Sm0",
        "outputId": "4b14cc2b-d19c-45ba-afa5-af6f66ca7247"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Artificial Intelligence (AI)**\n> \n> AI refers to the development and use of computer systems that are able to perform tasks that typically require human intelligence, such as:\n> \n> * **Learning:** Acquiring and understanding new information from data.\n> * **Reasoning:** Applying logic and deduction to solve problems or make decisions.\n> * **Problem-solving:** Defining and solving complex problems.\n> * **Perception:** Understanding and interpreting sensory data, such as images or speech.\n> * **Natural language processing:** Understanding and generating human language.\n> \n> **Types of AI:**\n> \n> * **Narrow AI:** Designed to perform specific tasks, such as playing chess or translating languages.\n> * **General AI:** Hypothetical machines that can perform a wide range of intellectual tasks at the level of a human.\n> * **Super AI:** AI that exceeds human intelligence in all domains.\n> \n> **Methods of AI:**\n> \n> * **Machine Learning:** Algorithms that learn patterns and make predictions from data.\n> * **Deep Learning:** A subset of machine learning that uses artificial neural networks to solve complex problems.\n> * **Natural Language Processing (NLP):** Techniques that allow computers to understand and process human language.\n> * **Computer Vision:** Methods for computers to analyze and interpret images and videos.\n> \n> **Applications of AI:**\n> \n> AI is used in a wide range of industries and applications, including:\n> \n> * Healthcare (diagnosis, treatment)\n> * Finance (fraud detection, risk assessment)\n> * Manufacturing (quality control, automation)\n> * Transportation (self-driving cars, route optimization)\n> * Customer service (chatbots, recommendation systems)\n> \n> **Benefits of AI:**\n> \n> * **Increased efficiency and productivity:** Automating tasks and providing insights.\n> * **Improved decision-making:** Providing data-driven recommendations and predictions.\n> * **Enhanced user experiences:** Personalizing interactions and making them more convenient.\n> * **New product and service innovation:** Enabling the development of previously impossible solutions.\n> \n> **Challenges and Ethical Considerations of AI:**\n> \n> * **Bias:** AI systems can inherit biases from their training data.\n> * **Job displacement:** AI can automate certain tasks, leading to job losses.\n> * **Privacy concerns:** AI can collect and analyze large amounts of data, raising privacy issues.\n> * **Misuse of AI:** AI can be used for malicious purposes, such as surveillance or manipulation."
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates\n",
        "\n",
        "#In the context of Gemini, response.candidates is likely a property within the response object that contains a list of potential or alternative responses."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1XjyeFm7JKf",
        "outputId": "d070ff3f-5da8-42ea-e26b-27298462a18f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[content {\n",
              "  parts {\n",
              "    text: \"**Artificial Intelligence (AI)**\\n\\nAI refers to the development and use of computer systems that are able to perform tasks that typically require human intelligence, such as:\\n\\n* **Learning:** Acquiring and understanding new information from data.\\n* **Reasoning:** Applying logic and deduction to solve problems or make decisions.\\n* **Problem-solving:** Defining and solving complex problems.\\n* **Perception:** Understanding and interpreting sensory data, such as images or speech.\\n* **Natural language processing:** Understanding and generating human language.\\n\\n**Types of AI:**\\n\\n* **Narrow AI:** Designed to perform specific tasks, such as playing chess or translating languages.\\n* **General AI:** Hypothetical machines that can perform a wide range of intellectual tasks at the level of a human.\\n* **Super AI:** AI that exceeds human intelligence in all domains.\\n\\n**Methods of AI:**\\n\\n* **Machine Learning:** Algorithms that learn patterns and make predictions from data.\\n* **Deep Learning:** A subset of machine learning that uses artificial neural networks to solve complex problems.\\n* **Natural Language Processing (NLP):** Techniques that allow computers to understand and process human language.\\n* **Computer Vision:** Methods for computers to analyze and interpret images and videos.\\n\\n**Applications of AI:**\\n\\nAI is used in a wide range of industries and applications, including:\\n\\n* Healthcare (diagnosis, treatment)\\n* Finance (fraud detection, risk assessment)\\n* Manufacturing (quality control, automation)\\n* Transportation (self-driving cars, route optimization)\\n* Customer service (chatbots, recommendation systems)\\n\\n**Benefits of AI:**\\n\\n* **Increased efficiency and productivity:** Automating tasks and providing insights.\\n* **Improved decision-making:** Providing data-driven recommendations and predictions.\\n* **Enhanced user experiences:** Personalizing interactions and making them more convenient.\\n* **New product and service innovation:** Enabling the development of previously impossible solutions.\\n\\n**Challenges and Ethical Considerations of AI:**\\n\\n* **Bias:** AI systems can inherit biases from their training data.\\n* **Job displacement:** AI can automate certain tasks, leading to job losses.\\n* **Privacy concerns:** AI can collect and analyze large amounts of data, raising privacy issues.\\n* **Misuse of AI:** AI can be used for malicious purposes, such as surveillance or manipulation.\"\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "index: 0\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.prompt_feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14nLi9N3-40L",
        "outputId": "6ee63c8e-980a-418f-862c-32a566d15d44"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = model.generate_content(\"what is meaning of line ?\", stream = True)\n",
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"==\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "9iH07hfI7JOA",
        "outputId": "8febc9a2-5ab7-432f-bc81-96507e4f43af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In general, a line is a one-dimensional object that extends infinitely in one\n",
            "================================================================================================================================================================\n",
            " direction. It can be straight or curved, and it can be represented by a mathematical equation.\n",
            "\n",
            "**In mathematics,** a line is a set of points that\n",
            "================================================================================================================================================================\n",
            " satisfy a linear equation. The equation of a line can be written in the form y = mx + b, where m is the slope of the line and b is the y-intercept.\n",
            "\n",
            "**In geometry,** a line is a straight path that connects two points. Lines can be parallel, perpendicular, or intersecting.\n",
            "================================================================================================================================================================\n",
            "\n",
            "\n",
            "**In computer graphics,** a line is a collection of pixels that are connected by a straight path. Lines can be used to create shapes, drawings, and other graphical objects.\n",
            "\n",
            "**In typography,** a line is a row of text. Lines can be justified, centered, or left-aligned.\n",
            "\n",
            "**In music,** a line is a melodic phrase or a series of notes that are played in sequence. Lines can be simple or complex, and they can be used to create melodies, harmonies, and rhythms.\n",
            "================================================================================================================================================================\n",
            "CPU times: user 77.4 ms, sys: 10.6 ms, total: 88 ms\n",
            "Wall time: 4.78 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image to text"
      ],
      "metadata": {
        "id": "1IK3lX9L99jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o image1.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIHD7D9m_MQw",
        "outputId": "a804bd0d-eda5-44d6-b258-b74a37a50db7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  405k  100  405k    0     0  3615k      0 --:--:-- --:--:-- --:--:-- 3649k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o image2.jpg https://images.pexels.com/photos/414612/pexels-photo-414612.jpeg?cs=srgb&dl=pexels-james-wheeler-414612.jpg&fm=jpg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQBtUE67Ak66",
        "outputId": "c2470595-f4df-4412-b958-ab0d98860d4b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1499k  100 1499k    0     0  1729k      0 --:--:-- --:--:-- --:--:-- 1729k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gNAaiimRAk97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import PIL.Image\n",
        "\n",
        "img1 = PIL.Image.open('image1.jpg')\n",
        "#img1\n",
        ""
      ],
      "metadata": {
        "id": "rgMXwj-eAlAV"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "img2 = PIL.Image.open('image2.jpg')\n",
        "#img2\n",
        ""
      ],
      "metadata": {
        "id": "FcFdeW12AlC_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE to text generation"
      ],
      "metadata": {
        "id": "F-RTxiSDMqqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = genai.GenerativeModel('models/gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "qs22YkS4FdSs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model1.generate_content(img1)"
      ],
      "metadata": {
        "id": "nDwVTPVkFdWC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "WUwUpwjmFdYz",
        "outputId": "9c9ac5c3-b277-4994-d144-1ccf55233a4b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> This is a beautiful picture of a wooden dock extending out into a still, blue lake under a starry sky. The full moon is shining brightly in the distance, reflecting on the water's surface. Tall trees line the shore of the lake and their reflections are mirrored in the water. The scene is serene and peaceful, conveying a sense of tranquility and solitude.  I love the way the moonlight illuminates the dock and the path leading to it. This photo would make a great piece of art!"
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = model1.generate_content(img2)"
      ],
      "metadata": {
        "id": "XHaIr6YTFdbb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response1.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "bIIzps4-KGHQ",
        "outputId": "84a0b71a-8a13-44d6-b8e0-22fc6a093e17"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> This is a beautiful and serene image of a wooden dock extending into a still lake under a starry night sky. The reflection of the stars in the water creates a magical effect. The soft glow of the moon adds to the peaceful atmosphere. The scene is reminiscent of a tranquil getaway, where one could escape the hustle and bustle of everyday life and reconnect with nature. The image evokes feelings of peace, tranquility, and wonder."
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeZVLK6CMIhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a bog based on image"
      ],
      "metadata": {
        "id": "_fL-madZMI4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = model1.generate_content([\"write a short engaging blog on this image\",img1],stream=True)"
      ],
      "metadata": {
        "id": "5wVevoyUK6Sl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to acculumate result\n",
        "response3.resolve()"
      ],
      "metadata": {
        "id": "2mim1w_ZLx1C"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response3.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "ejTYPt8uLjTv",
        "outputId": "bb8e4cc3-d3ca-402e-b995-044424e0f349"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ##  Meal Prep Made Easy: The Perfect Lunchbox Solution\n> \n> This image showcases a delicious and healthy meal prep solution that's perfect for anyone on the go. Two glass containers are filled with a variety of colorful and nutritious ingredients, making it easy to pack a balanced and satisfying lunch.\n> \n> The first container features a hearty mix of chicken, broccoli, carrots, red peppers, and rice, topped with a sprinkle of sesame seeds. The second container offers a similar combination with the addition of some fresh green onions. \n> \n> These meal prep containers are ideal for anyone looking to save time and money while enjoying a healthy and delicious meal. They're also perfect for busy individuals who need to eat on the run. \n> \n> **Here are some benefits of meal prepping:**\n> \n> * **Saves time:** By prepping your meals in advance, you can avoid spending time cooking every day.\n> * **Saves money:** Eating out less can help you save money on your food budget.\n> * **Promotes healthy eating:** Prepping your meals allows you to control the ingredients and portion sizes, ensuring that you're eating healthy and nutritious foods.\n> \n> **Tip:** You can customize your meal prep containers to include your favorite ingredients. Get creative and experiment with different combinations to find what you enjoy the most.\n> \n> So, what are you waiting for?  Start meal prepping today and enjoy the benefits of having delicious and healthy meals ready to go! \n"
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}